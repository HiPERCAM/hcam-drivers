#!/usr/bin/env python
from __future__ import print_function, division, unicode_literals

import glob
import os
import traceback

from astropy.io import fits
import tornado.ioloop
from tornado.escape import json_encode
from tornado.web import RequestHandler, Application, url


class FastFITSPipe:
    def __init__(self, fileobj, hdus_per_frame=5):
        """
        Simple class to quickly pull bytes from specified HDUs of a FITS file.

        The class is designed to quickly find a particular point in a multi-extension
        FITS file, and from then on to sequentially extract the bytes containing the
        next N HDUs.

        For example::

            >> fileobj = open('example.fits', 'rb')
            >> ffp = FastFITSPipe(fileobj, hdus_per_frame=5)
            >> ffp.seek_frame(100)
            >> hdu_bytes = ffp.read_frame_bytes()

        Parameters
        -----------
        fileobj : file-like object
            the file-like object representing a FITS file, readonly
        hdus_per_frame : int
            the number of FITS HDUs per frame
        """
        self._fileobj = fileobj
        self.hdus_per_frame = hdus_per_frame
        self.BLOCK_SIZE = 2880
        self.framesize_bytes = self._calc_frame_size()

    def read_frame_bytes(self):
        return self._fileobj.read(self.framesize_bytes)

    def _calc_frame_size(self):
        self._fileobj.seek(0)
        # primaryHDU
        self.priHDR = fits.Header.fromfile(self._fileobj)
        self.priHDR_size = self._fileobj.tell()
        for i in range(self.hdus_per_frame):
            self._skip_hdu()
        return self._fileobj.tell() - self.priHDR_size

    def seek_frame(self, nframe):
        """
        Move to the position in the file which pertains to the frame required
        """
        byte_location = self.priHDR_size + nframe*self.framesize_bytes
        self._fileobj.seek(byte_location)

    def _pad_length(self, stringlen):
        """Bytes needed to pad the input stringlen to the next FITS block."""
        return (self.BLOCK_SIZE - (stringlen % self.BLOCK_SIZE)) % self.BLOCK_SIZE

    def _skip_hdu(self):
        hdr = fits.Header.fromfile(self._fileobj)
        self._fileobj.seek(self._fileobj.tell() + self._hdu_size(hdr))

    def _hdu_size(self, hdr):
        size = 0
        naxis = hdr.get('NAXIS', 0)
        if naxis > 0:
            size = 1
            for idx in range(naxis):
                size = size * hdr['NAXIS' + str(idx + 1)]
            bitpix = hdr['BITPIX']
            gcount = hdr.get('GCOUNT', 1)
            pcount = hdr.get('PCOUNT', 0)
            size = abs(bitpix) * gcount * (pcount + size) // 8
        return size + self._pad_length(size)


class BaseHandler(RequestHandler):
    """
    Abstract class for request handling
    """
    def write_error(self, status_code, **kwargs):
        self.set_header('Content-Type', 'application/json')
        resp_dict = {'status_code': status_code, 'error': self._reason}
        if self.settings.get("serve_traceback") and "exc_info" in kwargs:
            lines = []
            for line in traceback.format_exception(*kwargs["exc_info"]):
                lines.append(line)
            resp_dict['traceback'] = lines
        self.finish(json_encode(resp_dict))


class MainHandler(BaseHandler):
    def initialize(self, db):
        self.db = db

    def get(self, path):
        try:
            action = self.get_argument('action')
        except:
            raise tornado.web.HTTPError(400)
        if action == "dir":
            self.list_dir(self.db['dir'], path)
        else:
            raise tornado.web.HTTPError(400)

    def list_dir(self, root, stub):
        path = os.path.abspath(os.path.join(root, stub, "*.fits"))
        files = [os.path.splitext(
                    os.path.basename(file))[0] for file in glob.glob(path)]
        self.write("\n".join(files))


class RunHandler(BaseHandler):
    def initialize(self, db):
        self.db = db  # global db used for state

    def _get_client_state(self, run_id):
        self.client_key = self.request.remote_ip
        # get state
        make_new_ffp = False
        try:
            prev_run_id = self.db[self.client_key]['run_id']
            if prev_run_id != run_id:
                self.run_id = run_id
                make_new_ffp = True
        except:
            self.run_id = run_id
            make_new_ffp = True

        if make_new_ffp:
            print('loading {} for client {}'.format(
                self.run_id, self.client_key
            ))
            self.ffp = self.get_ffp(self.run_id)
        else:
            self.ffp = self.db[self.client_key]['ffp']

    def on_finish(self):
        # TODO: how do we ever close open file handles??
        # save state for next request
        try:
            self.db[self.client_key] = dict(run_id=self.run_id, ffp=self.ffp)
        except:
            pass

    def get(self, run_id):
        # get some info about a given run
        action = self.get_argument('action')
        if action not in ['get_hdr', 'get_frame', 'get_next_frame']:
            raise tornado.web.HTTPError(400)
        self._get_client_state(run_id)
        try:
            if action == "get_hdr":
                try:
                    self.get_main_header()
                except:
                    raise tornado.web.HTTPError(400)
            elif action == "get_frame":
                try:
                    frame_id = int(self.get_argument('frame'))
                    self.get_frame(frame_id)
                except:
                    raise tornado.web.HTTPError(400)
            elif action == "get_next_frame":
                try:
                    self.get_next_frame()
                except:
                    raise tornado.web.HTTPError(400)
        except:
            raise tornado.web.HTTPError(400)

    def get_ffp(self, run_id):
        fname = '{}.fits'.format(run_id)
        path = os.path.join(self.db['dir'], fname)
        return FastFITSPipe(open(path, 'rb'), hdus_per_frame=5)

    def get_main_header(self):
        """
        Send main FITS HDU as txt
        """
        hdr = self.ffp.priHDR
        self.write(hdr.tostring(sep='\n').encode('UTF-8'))

    def get_frame(self, frame_id):
        """
        Read data from HDU in FITS file and send FITS HDUs as binary data
        """
        self.ffp.seek_frame(frame_id)
        self._send_frame()

    def _send_frame(self):
        fits_bytes = self.ffp.read_frame_bytes()
        # write the stuff
        self.set_header("Content-type",  "image/data")
        self.set_header('Content-length', len(fits_bytes))
        self.write(fits_bytes)

    def get_next_frame(self):
        self._send_frame()


def make_app(db, debug):
    return Application([
        # url routing. look for runXXX pattern first, assume everything else
        # is a directory for e.g uls
        url(r"/(run[0-9]+)", RunHandler, dict(db=db), name="run"),
        url(r"/(.*)", MainHandler, dict(db=db), name="path")
    ], debug=debug)


def run_fileserver(dir, debug):
    # we pass around current run and reference to open fits object
    # to minimise the overheads associated with each request.
    # this will break if the fileserver is run with multiple processes!
    db = {'dir': dir}
    app = make_app(db, debug)
    app.listen(8007)
    tornado.ioloop.IOLoop.current().start()


if __name__ == "__main__":
    import argparse
    parser = argparse.ArgumentParser(description="HiPERCAM FileServer")
    parser.add_argument('--dir', action='store', default='.', help="directory to serve")
    parser.add_argument('--debug', action='store_true', help="debug fileserver")
    args = parser.parse_args()
    run_fileserver(os.path.abspath(args.dir), args.debug)
